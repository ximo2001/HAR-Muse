{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: features_1.csv\n",
      "Optimized parameters for Random Forest: {'random_forest__max_depth': None, 'random_forest__min_samples_leaf': 2, 'random_forest__min_samples_split': 10, 'random_forest__n_estimators': 100, 'select_k_best__k': 41}\n",
      "Optimized cross-validation score: 0.87\n",
      "\n",
      "Processing file: features_4.csv\n",
      "Optimized parameters for Random Forest: {'random_forest__max_depth': 10, 'random_forest__min_samples_leaf': 6, 'random_forest__min_samples_split': 5, 'random_forest__n_estimators': 100, 'select_k_best__k': 41}\n",
      "Optimized cross-validation score: 0.85\n",
      "\n",
      "Processing file: features_3.csv\n",
      "Optimized parameters for Random Forest: {'random_forest__max_depth': 10, 'random_forest__min_samples_leaf': 6, 'random_forest__min_samples_split': 15, 'random_forest__n_estimators': 400, 'select_k_best__k': 26}\n",
      "Optimized cross-validation score: 0.85\n",
      "\n",
      "Processing file: features_2.csv\n",
      "Optimized parameters for Random Forest: {'random_forest__max_depth': None, 'random_forest__min_samples_leaf': 6, 'random_forest__min_samples_split': 15, 'random_forest__n_estimators': 100, 'select_k_best__k': 41}\n",
      "Optimized cross-validation score: 0.87\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, GroupKFold\n",
    "import os\n",
    "\n",
    "# Function to reduce features using SelectKBest\n",
    "def select_features(X_train, y_train, X_test, k=10):\n",
    "    # Initialize and fit SelectKBest\n",
    "    selector = SelectKBest(score_func=f_classif, k=k)\n",
    "    selector.fit(X_train, y_train)\n",
    "    \n",
    "    # Transform both training and testing data\n",
    "    X_train_reduced = selector.transform(X_train)\n",
    "    X_test_reduced = selector.transform(X_test)\n",
    "    \n",
    "    return X_train_reduced, X_test_reduced\n",
    "\n",
    "def run_rf_grid_search(features, labels, groups):\n",
    "    pipe = Pipeline([\n",
    "        ('select_k_best', SelectKBest(score_func=f_classif)),\n",
    "        ('random_forest', RandomForestClassifier())\n",
    "    ])\n",
    "\n",
    "    # Definir rangos para 'k' y otros hiperparámetros\n",
    "    k_range = list(range(5, 50, 3))\n",
    "    n_estimators_range = [100, 200, 300, 400]\n",
    "    max_depth_range = [None, 10, 20]\n",
    "    min_samples_split_range = [5, 10, 15]\n",
    "    min_samples_leaf_range = [2, 4, 6]\n",
    "\n",
    "    params = {\n",
    "        'select_k_best__k': k_range,\n",
    "        'random_forest__n_estimators': n_estimators_range,\n",
    "        'random_forest__max_depth': max_depth_range,\n",
    "        'random_forest__min_samples_split': min_samples_split_range,\n",
    "        'random_forest__min_samples_leaf': min_samples_leaf_range\n",
    "    }\n",
    "\n",
    "    group_kfold = GroupKFold(n_splits=5)\n",
    "    grid_search = GridSearchCV(pipe, param_grid=params, cv=group_kfold, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(features, labels, groups=groups)\n",
    "    \n",
    "    print(\"Optimized parameters for Random Forest:\", grid_search.best_params_)\n",
    "    print(\"Optimized cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "def process_file(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df[df['label'].isin([0, 2])]  # Filtrar solo etiquetas 0 y 2\n",
    "    labels = df['label']\n",
    "    features = df.drop(columns=['subject_id', 'label'])\n",
    "    groups = df['subject_id']  # Esta será la base para el GroupKFold\n",
    "    run_rf_grid_search(features, labels, groups)\n",
    "\n",
    "def main(folder_path):\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.startswith(\"features_\") and file_name.endswith(\".csv\"):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            print(f\"\\nProcessing file: {file_name}\")\n",
    "            process_file(file_path)\n",
    "\n",
    "# Cambia la ruta según corresponda\n",
    "main('/home/ximo/Escritorio/ProyectoTFG/featuresExtended')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, GroupKFold\n",
    "import os\n",
    "\n",
    "# Function to reduce features using SelectKBest\n",
    "def select_features(X_train, y_train, X_test, k=10):\n",
    "    # Initialize and fit SelectKBest\n",
    "    selector = SelectKBest(score_func=f_classif, k=k)\n",
    "    selector.fit(X_train, y_train)\n",
    "    \n",
    "    # Transform both training and testing data\n",
    "    X_train_reduced = selector.transform(X_train)\n",
    "    X_test_reduced = selector.transform(X_test)\n",
    "    \n",
    "    return X_train_reduced, X_test_reduced\n",
    "\n",
    "def run_rf_grid_search(features, labels, groups):\n",
    "    pipe = Pipeline([\n",
    "        ('select_k_best', SelectKBest(score_func=f_classif)),\n",
    "        ('random_forest', RandomForestClassifier())\n",
    "    ])\n",
    "\n",
    "    # Definir rangos para 'k' y otros hiperparámetros\n",
    "    k_range = list(range(26, 60, 1))\n",
    "    n_estimators_range = [100, 200, 400]\n",
    "    max_depth_range = [None, 10]\n",
    "    min_samples_split_range = [5, 10, 15, 20]\n",
    "    min_samples_leaf_range = [2, 6, 8]\n",
    "\n",
    "    params = {\n",
    "        'select_k_best__k': k_range,\n",
    "        'random_forest__n_estimators': n_estimators_range,\n",
    "        'random_forest__max_depth': max_depth_range,\n",
    "        'random_forest__min_samples_split': min_samples_split_range,\n",
    "        'random_forest__min_samples_leaf': min_samples_leaf_range\n",
    "    }\n",
    "\n",
    "    group_kfold = GroupKFold(n_splits=30)\n",
    "    grid_search = GridSearchCV(pipe, param_grid=params, cv=group_kfold, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(features, labels, groups=groups)\n",
    "    \n",
    "    print(\"Optimized parameters for Random Forest:\", grid_search.best_params_)\n",
    "    print(\"Optimized cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "def process_file(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df[df['label'].isin([0, 2])]  # Filtrar solo etiquetas 0 y 2\n",
    "    labels = df['label']\n",
    "    features = df.drop(columns=['subject_id', 'label'])\n",
    "    groups = df['subject_id']  # Esta será la base para el GroupKFold\n",
    "    run_rf_grid_search(features, labels, groups)\n",
    "\n",
    "def main(folder_path):\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.startswith(\"features_\") and file_name.endswith(\".csv\"):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            print(f\"\\nProcessing file: {file_name}\")\n",
    "            process_file(file_path)\n",
    "\n",
    "# Cambia la ruta según corresponda\n",
    "main('/home/ximo/Escritorio/ProyectoTFG/featuresExtended')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing file: features_1.csv\n",
    "Optimized parameters for Random Forest: {'random_forest__max_depth': 10, 'random_forest__min_samples_leaf': 2, 'random_forest__min_samples_split': 5, 'random_forest__n_estimators': 200, 'select_k_best__k': 57}\n",
    "Optimized cross-validation score: 0.88\n",
    "\n",
    "Processing file: features_4.csv\n",
    "Optimized parameters for Random Forest: {'random_forest__max_depth': None, 'random_forest__min_samples_leaf': 8, 'random_forest__min_samples_split': 15, 'random_forest__n_estimators': 200, 'select_k_best__k': 37}\n",
    "Optimized cross-validation score: 0.86\n",
    "\n",
    "Processing file: features_2.csv\n",
    "Optimized parameters for Random Forest: {'random_forest__max_depth': 10, 'random_forest__min_samples_leaf': 8, 'random_forest__min_samples_split': 10, 'random_forest__n_estimators': 100, 'select_k_best__k': 33}\n",
    "Optimized cross-validation score: 0.88\n",
    "\n",
    "Processing file: features_3.csv\n",
    "Optimized parameters for Random Forest: {'random_forest__max_depth': None, 'random_forest__min_samples_leaf': 2, 'random_forest__min_samples_split': 20, 'random_forest__n_estimators': 200, 'select_k_best__k': 27}\n",
    "Optimized cross-validation score: 0.86\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: features_1.csv\n",
      "Optimized parameters for Random Forest: {'random_forest__max_depth': None, 'random_forest__min_samples_leaf': 2, 'random_forest__min_samples_split': 5, 'random_forest__n_estimators': 100, 'select_k_best__k': 123}\n",
      "Optimized cross-validation score: 0.88\n",
      "\n",
      "Processing file: features_4.csv\n",
      "Optimized parameters for Random Forest: {'random_forest__max_depth': 10, 'random_forest__min_samples_leaf': 2, 'random_forest__min_samples_split': 5, 'random_forest__n_estimators': 100, 'select_k_best__k': 133}\n",
      "Optimized cross-validation score: 0.87\n",
      "\n",
      "Processing file: features_3.csv\n",
      "Optimized parameters for Random Forest: {'random_forest__max_depth': 10, 'random_forest__min_samples_leaf': 2, 'random_forest__min_samples_split': 20, 'random_forest__n_estimators': 100, 'select_k_best__k': 140}\n",
      "Optimized cross-validation score: 0.86\n",
      "\n",
      "Processing file: features_2.csv\n",
      "Optimized parameters for Random Forest: {'random_forest__max_depth': None, 'random_forest__min_samples_leaf': 8, 'random_forest__min_samples_split': 5, 'random_forest__n_estimators': 100, 'select_k_best__k': 61}\n",
      "Optimized cross-validation score: 0.88\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, GroupKFold\n",
    "import os\n",
    "\n",
    "# Function to reduce features using SelectKBest\n",
    "def select_features(X_train, y_train, X_test, k=10):\n",
    "    # Initialize and fit SelectKBest\n",
    "    selector = SelectKBest(score_func=f_classif, k=k)\n",
    "    selector.fit(X_train, y_train)\n",
    "    \n",
    "    # Transform both training and testing data\n",
    "    X_train_reduced = selector.transform(X_train)\n",
    "    X_test_reduced = selector.transform(X_test)\n",
    "    \n",
    "    return X_train_reduced, X_test_reduced\n",
    "\n",
    "def run_rf_grid_search(features, labels, groups):\n",
    "    pipe = Pipeline([\n",
    "        ('select_k_best', SelectKBest(score_func=f_classif)),\n",
    "        ('random_forest', RandomForestClassifier())\n",
    "    ])\n",
    "\n",
    "    # Definir rangos para 'k' y otros hiperparámetros\n",
    "    k_range = list(range(60, features.shape[1]+1, 1))\n",
    "    n_estimators_range = [100, 200]\n",
    "    max_depth_range = [None, 10]\n",
    "    min_samples_split_range = [5, 10, 15, 20]\n",
    "    min_samples_leaf_range = [2, 8]\n",
    "\n",
    "    params = {\n",
    "        'select_k_best__k': k_range,\n",
    "        'random_forest__n_estimators': n_estimators_range,\n",
    "        'random_forest__max_depth': max_depth_range,\n",
    "        'random_forest__min_samples_split': min_samples_split_range,\n",
    "        'random_forest__min_samples_leaf': min_samples_leaf_range\n",
    "    }\n",
    "\n",
    "    group_kfold = GroupKFold(n_splits=30)\n",
    "    grid_search = GridSearchCV(pipe, param_grid=params, cv=group_kfold, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(features, labels, groups=groups)\n",
    "    \n",
    "    print(\"Optimized parameters for Random Forest:\", grid_search.best_params_)\n",
    "    print(\"Optimized cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "def process_file(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df[df['label'].isin([0, 2])]  # Filtrar solo etiquetas 0 y 2\n",
    "    labels = df['label']\n",
    "    features = df.drop(columns=['subject_id', 'label'])\n",
    "    groups = df['subject_id']  # Esta será la base para el GroupKFold\n",
    "    run_rf_grid_search(features, labels, groups)\n",
    "\n",
    "def main(folder_path):\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.startswith(\"features_\") and file_name.endswith(\".csv\"):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            print(f\"\\nProcessing file: {file_name}\")\n",
    "            process_file(file_path)\n",
    "\n",
    "# Cambia la ruta según corresponda\n",
    "main('/home/ximo/Escritorio/ProyectoTFG/featuresExtended')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GroupKFold, train_test_split\n",
    "\n",
    "# Directorio base y modelo\n",
    "folder_path = '/home/ximo/Escritorio/ProyectoTFG/featuresExtended'\n",
    "output_path = '/home/ximo/Escritorio/ProyectoTFG/resultsBINMUSICA'\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier\n",
    "}\n",
    "\n",
    "# Parámetros optimizados para Random Forest\n",
    "optimized_parameters = {\n",
    "    \"features_1.csv\": {'random_forest__max_depth': None, 'random_forest__min_samples_leaf': 2, 'random_forest__min_samples_split': 5, 'random_forest__n_estimators': 100, 'select_k_best__k': 123},\n",
    "    \"features_4.csv\": {'random_forest__max_depth': 10, 'random_forest__min_samples_leaf': 2, 'random_forest__min_samples_split': 5, 'random_forest__n_estimators': 100, 'select_k_best__k': 133},\n",
    "    \"features_3.csv\": {'random_forest__max_depth': 10, 'random_forest__min_samples_leaf': 2, 'random_forest__min_samples_split': 20, 'random_forest__n_estimators': 100, 'select_k_best__k': 140},\n",
    "    \"features_2.csv\": {'random_forest__max_depth': None, 'random_forest__min_samples_leaf': 8, 'random_forest__min_samples_split': 5, 'random_forest__n_estimators': 100, 'select_k_best__k': 61}\n",
    "}\n",
    "\n",
    "\n",
    "# Funciones auxiliares\n",
    "def create_unique_file_path(base_path, filename):\n",
    "    counter = 1\n",
    "    original_filename = filename\n",
    "    while os.path.exists(os.path.join(base_path, filename)):\n",
    "        filename = f\"{os.path.splitext(original_filename)[0]}({counter}){os.path.splitext(original_filename)[1]}\"\n",
    "        counter += 1\n",
    "    return os.path.join(base_path, filename)\n",
    "\n",
    "def process_and_evaluate(file_path, models, optimized_parameters, output_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df[df['label'].isin([0, 2])]  # Filtrar solo etiquetas 0 y 2\n",
    "    features = df.drop(columns=['subject_id', 'label'])\n",
    "    labels = df['label']\n",
    "    subjects = df['subject_id']\n",
    "    num_windows = file_path.split('_')[-1].split('.')[0]\n",
    "\n",
    "    file_name = os.path.basename(file_path)\n",
    "    if file_name in optimized_parameters:\n",
    "        params = optimized_parameters[file_name]\n",
    "        model_name = \"Random Forest\"\n",
    "        k = params.pop('select_k_best__k')\n",
    "        evaluate_and_save_results(features, labels, subjects, models, model_name, params, k, output_path, num_windows)\n",
    "\n",
    "def evaluate_and_save_results(features, labels, subjects, models, model_name, model_params, k, output_path, num_windows):\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    \n",
    "    selector = SelectKBest(f_classif, k=k)\n",
    "    selected_features = selector.fit_transform(features, labels)\n",
    "    gkf = GroupKFold(n_splits=len(np.unique(subjects)))\n",
    "\n",
    "    clean_params = {key.split('__')[-1]: value for key, value in model_params.items()}\n",
    "    model_cls = models[model_name]\n",
    "    model = model_cls(**clean_params)\n",
    "    cm_global = np.zeros((2, 2))\n",
    "    model_times = []\n",
    "\n",
    "    for train_idx, test_idx in gkf.split(selected_features, labels, groups=subjects):\n",
    "        X_train, X_test = selected_features[train_idx], selected_features[test_idx]\n",
    "        y_train, y_test = labels.iloc[train_idx], labels.iloc[test_idx]\n",
    "\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        end_time = time.time()\n",
    "        predictions = model.predict(X_test)\n",
    "        model_time = end_time - start_time\n",
    "        model_times.append(model_time)\n",
    "\n",
    "        cm = confusion_matrix(y_test, predictions, labels=[0, 2])\n",
    "        cm_global += cm\n",
    "\n",
    "    cm_df = pd.DataFrame(cm_global, index=[0, 2], columns=[0, 2])\n",
    "    filename = f\"conf_matrix_{num_windows}_{model_name}_{k}.csv\"\n",
    "    unique_file_path = create_unique_file_path(output_path, filename)\n",
    "    cm_df.to_csv(unique_file_path)\n",
    "\n",
    "    average_time = sum(model_times)\n",
    "    times_file_path = f\"{output_path}/model_times.csv\"\n",
    "    header = not os.path.exists(times_file_path)\n",
    "    with open(times_file_path, \"a\") as f:\n",
    "        if header:\n",
    "            f.write(\"Model,Window,K,Time(s)\\n\")\n",
    "        f.write(f\"{model_name},{num_windows},{k},{average_time:.2f}\\n\")\n",
    "\n",
    "# Procesamiento principal\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.startswith(\"features_\") and file_name.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        process_and_evaluate(file_path, models, optimized_parameters, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
