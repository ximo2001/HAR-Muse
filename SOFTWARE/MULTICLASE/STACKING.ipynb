{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Diccionario con parámetros optimizados\n",
    "optimized_parameters = {\n",
    "    \"features_1.csv\": {\n",
    "        \"HistGradientBoosting\": {'histgb__learning_rate': 0.05, 'histgb__max_depth': None, 'histgb__max_iter': 200, 'histgb__min_samples_leaf': 20, 'select_k_best__k': 38},\n",
    "        \"CatBoost\": {'catboost__depth': 6, 'catboost__iterations': 200, 'catboost__l2_leaf_reg': 3, 'catboost__learning_rate': 0.05, 'select_k_best__k': 41},\n",
    "        \"ExtraTrees\": {'et__max_depth': None, 'et__min_samples_split': 15, 'et__n_estimators': 100, 'select_k_best__k': 43},\n",
    "        \"Random Forest\": {'random_forest__max_depth': 10, 'random_forest__min_samples_leaf': 4, 'random_forest__min_samples_split': 10, 'random_forest__n_estimators': 300, 'select_k_best__k': 39},\n",
    "        \"XGBoost\": {'select_k_best__k': 44, 'xgb__learning_rate': 0.05, 'xgb__max_depth': 7, 'xgb__n_estimators': 300},\n",
    "        \"KNN\": {'knn__algorithm': 'auto', 'knn__n_neighbors': 49, 'knn__weights': 'distance', 'select_k_best__k': 8},\n",
    "        \"AdaBoost\": {'adaboost__learning_rate': 0.1, 'adaboost__n_estimators': 200, 'select_k_best__k': 37},\n",
    "        \"MLP\": {'mlp__activation': 'relu', 'mlp__alpha': 0.01, 'mlp__early_stopping': True, 'mlp__hidden_layer_sizes': (100,), 'mlp__n_iter_no_change': 20, 'mlp__solver': 'adam', 'mlp__validation_fraction': 0.1, 'select_k_best__k': 31},\n",
    "        \"GaussianNB\": {'gnb__var_smoothing': 0.001, 'select_k_best__k': 28},\n",
    "        \"SVM\": {'select_k_best__k': 44, 'svm__C': 250, 'svm__loss': 'squared_hinge', 'svm__penalty': 'l1'}\n",
    "    },\n",
    "    \"features_4.csv\": {\n",
    "        \"HistGradientBoosting\": {'histgb__learning_rate': 0.05, 'histgb__max_depth': 5, 'histgb__max_iter': 200, 'histgb__min_samples_leaf': 40, 'select_k_best__k': 38},\n",
    "        \"CatBoost\": {'catboost__depth': 4, 'catboost__iterations': 200, 'catboost__l2_leaf_reg': 3, 'catboost__learning_rate': 0.05, 'select_k_best__k': 42},\n",
    "        \"ExtraTrees\": {'et__max_depth': None, 'et__min_samples_split': 10, 'et__n_estimators': 100, 'select_k_best__k': 28},\n",
    "        \"Random Forest\": {'random_forest__max_depth': 20, 'random_forest__min_samples_leaf': 4, 'random_forest__min_samples_split': 2, 'random_forest__n_estimators': 300, 'select_k_best__k': 38},\n",
    "        \"XGBoost\": {'select_k_best__k': 41, 'xgb__learning_rate': 0.05, 'xgb__max_depth': 3, 'xgb__n_estimators': 100},\n",
    "        \"KNN\": {'knn__algorithm': 'auto', 'knn__n_neighbors': 35, 'knn__weights': 'uniform', 'select_k_best__k': 8},\n",
    "        \"AdaBoost\": {'adaboost__learning_rate': 0.1, 'adaboost__n_estimators': 100, 'select_k_best__k': 38},\n",
    "        \"MLP\": {'mlp__activation': 'relu', 'mlp__alpha': 0.3, 'mlp__early_stopping': True, 'mlp__hidden_layer_sizes': (150,), 'mlp__n_iter_no_change': 20, 'mlp__solver': 'adam', 'mlp__validation_fraction': 0.1, 'select_k_best__k': 12},\n",
    "        \"GaussianNB\": {'gnb__var_smoothing': 0.0001, 'select_k_best__k': 22},\n",
    "        \"SVM\": {'select_k_best__k': 50, 'svm__C': 250, 'svm__loss': 'squared_hinge', 'svm__penalty': 'l1'}\n",
    "    },\n",
    "    \"features_3.csv\": {\n",
    "        \"HistGradientBoosting\": {'histgb__learning_rate': 0.01, 'histgb__max_depth': 5, 'histgb__max_iter': 200, 'histgb__min_samples_leaf': 20, 'select_k_best__k': 33},\n",
    "        \"CatBoost\": {'catboost__depth': 4, 'catboost__iterations': 200, 'catboost__l2_leaf_reg': 3, 'catboost__learning_rate': 0.05, 'select_k_best__k': 35},\n",
    "        \"ExtraTrees\": {'et__max_depth': None, 'et__min_samples_split': 15, 'et__n_estimators': 100, 'select_k_best__k': 38},\n",
    "        \"Random Forest\": {'random_forest__max_depth': 10, 'random_forest__min_samples_leaf': 4, 'random_forest__min_samples_split': 2, 'random_forest__n_estimators': 300, 'select_k_best__k': 38},\n",
    "        \"XGBoost\": {'select_k_best__k': 35, 'xgb__learning_rate': 0.01, 'xgb__max_depth': 3, 'xgb__n_estimators': 300},\n",
    "        \"KNN\": {'knn__algorithm': 'brute', 'knn__n_neighbors': 23, 'knn__weights': 'distance', 'select_k_best__k': 5},\n",
    "        \"AdaBoost\": {'adaboost__learning_rate': 0.1, 'adaboost__n_estimators': 150, 'select_k_best__k': 35},\n",
    "        \"MLP\": {'mlp__activation': 'relu', 'mlp__alpha': 0.3, 'mlp__early_stopping': True, 'mlp__hidden_layer_sizes': (200,), 'mlp__n_iter_no_change': 20, 'mlp__solver': 'adam', 'mlp__validation_fraction': 0.1, 'select_k_best__k': 29},\n",
    "        \"GaussianNB\": {'gnb__var_smoothing': 0.0001, 'select_k_best__k': 25},\n",
    "        \"SVM\": {'select_k_best__k': 46, 'svm__C': 250, 'svm__loss': 'squared_hinge', 'svm__penalty': 'l1'}\n",
    "    },\n",
    "    \"features_2.csv\": {\n",
    "        \"HistGradientBoosting\": {'histgb__learning_rate': 0.01, 'histgb__max_depth': 10, 'histgb__max_iter': 200, 'histgb__min_samples_leaf': 20, 'select_k_best__k': 33},\n",
    "        \"CatBoost\": {'catboost__depth': 4, 'catboost__iterations': 200, 'catboost__l2_leaf_reg': 3, 'catboost__learning_rate': 0.1, 'select_k_best__k': 41},\n",
    "        \"ExtraTrees\": {'et__max_depth': None, 'et__min_samples_split': 15, 'et__n_estimators': 200, 'select_k_best__k': 36},\n",
    "        \"Random Forest\": {'random_forest__max_depth': 10, 'random_forest__min_samples_leaf': 4, 'random_forest__min_samples_split': 10, 'random_forest__n_estimators': 300, 'select_k_best__k': 39},\n",
    "        \"XGBoost\": {'select_k_best__k': 35, 'xgb__learning_rate': 0.01, 'xgb__max_depth': 3, 'xgb__n_estimators': 200},\n",
    "        \"KNN\": {'knn__algorithm': 'auto', 'knn__n_neighbors': 15, 'knn__weights': 'uniform', 'select_k_best__k': 5},\n",
    "        \"AdaBoost\": {'adaboost__learning_rate': 0.1, 'adaboost__n_estimators': 150, 'select_k_best__k': 38},\n",
    "        \"MLP\": {'mlp__activation': 'relu', 'mlp__alpha': 0.1, 'mlp__early_stopping': True, 'mlp__hidden_layer_sizes': (100,), 'mlp__n_iter_no_change': 20, 'mlp__solver': 'adam', 'mlp__validation_fraction': 0.1, 'select_k_best__k': 17},\n",
    "        \"GaussianNB\": {'gnb__var_smoothing': 0.0001, 'select_k_best__k': 28},\n",
    "        \"SVM\": {'select_k_best__k': 39, 'svm__C': 100, 'svm__loss': 'squared_hinge', 'svm__penalty': 'l1'}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Modelos base\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier,\n",
    "    \"XGBoost\": xgb.XGBClassifier,\n",
    "    \"HistGradientBoosting\": HistGradientBoostingClassifier,\n",
    "    \"CatBoost\": CatBoostClassifier,\n",
    "    \"ExtraTrees\": ExtraTreesClassifier,\n",
    "    \"KNN\": KNeighborsClassifier,\n",
    "    \"AdaBoost\": AdaBoostClassifier,\n",
    "    \"MLP\": MLPClassifier,\n",
    "    \"GaussianNB\": GaussianNB,\n",
    "    \"SVM\": LinearSVC,\n",
    "}\n",
    "\n",
    "# Crear clasificadores base con los hiperparámetros optimizados\n",
    "def create_base_classifiers(file_name):\n",
    "    base_classifiers = []\n",
    "    for model_name, params in optimized_parameters[file_name].items():\n",
    "        clean_params = {key.split('__')[-1]: value for key, value in params.items() if key != 'select_k_best__k'}\n",
    "\n",
    "        # Ajuste específico para SVM\n",
    "        if model_name == \"SVM\":\n",
    "            clean_params['dual'] = False  # Asegurarse de que dual=False cuando penalty='l1'\n",
    "\n",
    "        model_cls = models[model_name]\n",
    "        model = model_cls(**clean_params)\n",
    "        base_classifiers.append((model_name, model))\n",
    "    return base_classifiers\n",
    "\n",
    "# Function to create a unique file path if the file already exists\n",
    "def create_unique_file_path(base_path, filename):\n",
    "    counter = 1\n",
    "    original_filename = filename\n",
    "    while os.path.exists(os.path.join(base_path, filename)):\n",
    "        filename = f\"{os.path.splitext(original_filename)[0]}({counter}){os.path.splitext(original_filename)[1]}\"\n",
    "        counter += 1\n",
    "    return os.path.join(base_path, filename)\n",
    "\n",
    "# Function to perform evaluation for a given k and write the results to a file\n",
    "def evaluate_and_save_results(features, labels, subjects, model, model_name, k, output_path, num_windows):\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    selector = SelectKBest(f_classif, k=k)\n",
    "    selected_features = selector.fit_transform(features, labels)\n",
    "    gkf = GroupKFold(n_splits=len(np.unique(subjects)))\n",
    "\n",
    "    cm_global = np.zeros((4, 4))  # Ajusta el tamaño según el número de etiquetas únicas\n",
    "    model_times = []\n",
    "\n",
    "    for train_idx, test_idx in gkf.split(selected_features, labels, groups=subjects):\n",
    "        X_train, X_test = selected_features[train_idx], selected_features[test_idx]\n",
    "        y_train, y_test = labels.iloc[train_idx], labels.iloc[test_idx]\n",
    "\n",
    "        start_time = time.time()\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", ConvergenceWarning)\n",
    "            model.fit(X_train, y_train)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        predictions = model.predict(X_test)\n",
    "        model_time = end_time - start_time\n",
    "        model_times.append(model_time)\n",
    "\n",
    "        cm = confusion_matrix(y_test, predictions, labels=[0, 1, 2, 3])\n",
    "        cm_global += cm  # Acumular resultados de la matriz de confusión\n",
    "\n",
    "    cm_df = pd.DataFrame(cm_global, index=[0, 1, 2, 3], columns=[0, 1, 2, 3])\n",
    "    filename = f\"conf_matrix_{num_windows}_{model_name}_{k}.csv\"\n",
    "    unique_file_path = create_unique_file_path(output_path, filename)\n",
    "    cm_df.to_csv(unique_file_path)\n",
    "\n",
    "    # Guardar el tiempo de ejecución del modelo\n",
    "    average_time = sum(model_times)\n",
    "    times_file_path = f\"{output_path}/model_times.csv\"\n",
    "    header = not os.path.exists(times_file_path)  # Comprueba si el archivo ya existe\n",
    "    with open(times_file_path, \"a\") as f:\n",
    "        if header:\n",
    "            f.write(\"Model,Window,K,Time(s)\\n\")  # Escribe los encabezados si el archivo no existe\n",
    "            \n",
    "        f.write(f\"{model_name},{num_windows},{k},{average_time}\\n\")\n",
    "\n",
    "# Main processing and evaluation function\n",
    "def process_and_evaluate(file_path, models, optimized_parameters, output_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    drop_cols = ['subject_id', 'label']\n",
    "    features = df.drop(columns=drop_cols)\n",
    "    labels = df['label']\n",
    "    subjects = df['subject_id']\n",
    "    num_windows = file_path.split('_')[-1].split('.')[0]  # Extract number of windows from filename\n",
    "\n",
    "    file_name = os.path.basename(file_path)\n",
    "    if file_name in optimized_parameters:\n",
    "        base_classifiers = create_base_classifiers(file_name)\n",
    "        \n",
    "        for k in [33,35,37,39,41,43,45,50]:  # Bucle desde k=33 hasta k=45            \n",
    "            # Stacking Classifier\n",
    "            stacking_model = StackingClassifier(estimators=base_classifiers, final_estimator=RandomForestClassifier(n_estimators=100))\n",
    "            evaluate_and_save_results(features, labels, subjects, stacking_model, 'StackingClassifier', k, output_path, num_windows)\n",
    "            \n",
    "\n",
    "# Run the processing\n",
    "folder_path = '/home/ximo/Escritorio/ProyectoTFG/featuresExtended'\n",
    "output_path = '/home/ximo/Escritorio/ProyectoTFG/results'\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.startswith(\"features_\") and file_name.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        process_and_evaluate(file_path, models, optimized_parameters, output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
