{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","from sklearn.svm import SVC\n","from sklearn.svm import LinearSVC\n","from sklearn.ensemble import RandomForestClassifier\n","import xgboost as xgb\n","from sklearn.model_selection import LeaveOneOut, cross_val_score, GroupKFold, GridSearchCV\n","from sklearn.metrics import accuracy_score\n","from sklearn.neighbors import KNeighborsClassifier\n","from tabulate import tabulate\n","from sklearn.metrics import confusion_matrix\n","from sklearn.feature_selection import SelectKBest, f_classif\n","from scipy.fft import fft\n","import time\n","from pyentrp import entropy as ent\n","import warnings\n","from sklearn.exceptions import ConvergenceWarning\n","import csv\n","from sklearn.pipeline import Pipeline"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Function to reduce features using SelectKBest\n","def select_features(X_train, y_train, X_test, k=10):\n","    # Initialize and fit SelectKBest\n","    selector = SelectKBest(score_func=f_classif, k=k)\n","    selector.fit(X_train, y_train)\n","    \n","    # Transform both training and testing data\n","    X_train_reduced = selector.transform(X_train)\n","    X_test_reduced = selector.transform(X_test)\n","    \n","    return X_train_reduced, X_test_reduced"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Processing file: features_1.csv\n"]},{"name":"stdout","output_type":"stream","text":["Optimized parameters for Random Forest: {'random_forest__max_depth': 10, 'random_forest__min_samples_leaf': 4, 'random_forest__min_samples_split': 10, 'random_forest__n_estimators': 300, 'select_k_best__k': 39}\n","Optimized cross-validation score: 0.55\n","\n","Processing file: features_4.csv\n","Optimized parameters for Random Forest: {'random_forest__max_depth': 20, 'random_forest__min_samples_leaf': 4, 'random_forest__min_samples_split': 2, 'random_forest__n_estimators': 300, 'select_k_best__k': 38}\n","Optimized cross-validation score: 0.53\n","\n","Processing file: features_3.csv\n","Optimized parameters for Random Forest: {'random_forest__max_depth': 10, 'random_forest__min_samples_leaf': 4, 'random_forest__min_samples_split': 2, 'random_forest__n_estimators': 300, 'select_k_best__k': 38}\n","Optimized cross-validation score: 0.54\n","\n","Processing file: features_2.csv\n","Optimized parameters for Random Forest: {'random_forest__max_depth': 10, 'random_forest__min_samples_leaf': 4, 'random_forest__min_samples_split': 10, 'random_forest__n_estimators': 300, 'select_k_best__k': 39}\n","Optimized cross-validation score: 0.55\n"]}],"source":["import pandas as pd\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_selection import SelectKBest, f_classif\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import GridSearchCV\n","\n","def run_rf_grid_search(features, labels):\n","    pipe = Pipeline([\n","        ('select_k_best', SelectKBest(score_func=f_classif)),\n","        ('random_forest', RandomForestClassifier())\n","    ])\n","\n","    # Definir rangos para 'k' con saltos de 5 en 5, ajusta según necesidad\n","    k_range = list(range(20, min(40, features.shape[1] + 1), 1))\n","\n","    params = {\n","        'select_k_best__k': k_range,\n","        'random_forest__n_estimators': [300],\n","\n","        'random_forest__max_depth': [None, 10, 20],\n","        'random_forest__min_samples_split': [2, 5, 10],\n","        'random_forest__min_samples_leaf': [1, 2, 4]\n","    }\n","\n","    grid_search = GridSearchCV(pipe, param_grid=params, cv=5, scoring='accuracy', n_jobs=-1)\n","    grid_search.fit(features, labels)\n","    \n","    print(\"Optimized parameters for Random Forest:\", grid_search.best_params_)\n","    print(\"Optimized cross-validation score: {:.2f}\".format(grid_search.best_score_))\n","\n","def process_file(file_path):\n","    df = pd.read_csv(file_path)\n","    labels = df['label']\n","    features = df.drop(columns=['subject_id', 'label'])\n","    run_rf_grid_search(features, labels)\n","\n","def main(folder_path):\n","    import os\n","    for file_name in os.listdir(folder_path):\n","        if file_name.startswith(\"features_\") and file_name.endswith(\".csv\"):\n","            file_path = os.path.join(folder_path, file_name)\n","            print(f\"\\nProcessing file: {file_name}\")\n","            process_file(file_path)\n","\n","# Cambia la ruta según corresponda\n","main('/home/ximo/Escritorio/ProyectoTFG/featuresExtended')\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Processing file: features_1.csv\n","Optimized parameters for Random Forest: {'random_forest__max_depth': 10, 'random_forest__min_samples_leaf': 6, 'random_forest__min_samples_split': 2, 'random_forest__n_estimators': 300, 'select_k_best__k': 49}\n","Optimized cross-validation score: 0.56\n","\n","Processing file: features_4.csv\n","Optimized parameters for Random Forest: {'random_forest__max_depth': 20, 'random_forest__min_samples_leaf': 2, 'random_forest__min_samples_split': 10, 'random_forest__n_estimators': 300, 'select_k_best__k': 49}\n","Optimized cross-validation score: 0.55\n","\n","Processing file: features_3.csv\n","Optimized parameters for Random Forest: {'random_forest__max_depth': 20, 'random_forest__min_samples_leaf': 2, 'random_forest__min_samples_split': 2, 'random_forest__n_estimators': 300, 'select_k_best__k': 50}\n","Optimized cross-validation score: 0.55\n","\n","Processing file: features_2.csv\n","Optimized parameters for Random Forest: {'random_forest__max_depth': 20, 'random_forest__min_samples_leaf': 6, 'random_forest__min_samples_split': 10, 'random_forest__n_estimators': 300, 'select_k_best__k': 42}\n","Optimized cross-validation score: 0.56\n"]}],"source":["import pandas as pd\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_selection import SelectKBest, f_classif\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import GridSearchCV\n","\n","def run_rf_grid_search(features, labels):\n","    pipe = Pipeline([\n","        ('select_k_best', SelectKBest(score_func=f_classif)),\n","        ('random_forest', RandomForestClassifier())\n","    ])\n","\n","    # Definir rangos para 'k' con saltos de 5 en 5, ajusta según necesidad\n","    k_range = list(range(40, 51, 1))\n","\n","    params = {\n","        'select_k_best__k': k_range,\n","        'random_forest__n_estimators': [300],\n","\n","        'random_forest__max_depth': [None, 10, 20],\n","        'random_forest__min_samples_split': [2, 5, 10],\n","        'random_forest__min_samples_leaf': [2, 4, 6]\n","    }\n","\n","    grid_search = GridSearchCV(pipe, param_grid=params, cv=5, scoring='accuracy', n_jobs=-1)\n","    grid_search.fit(features, labels)\n","    \n","    print(\"Optimized parameters for Random Forest:\", grid_search.best_params_)\n","    print(\"Optimized cross-validation score: {:.2f}\".format(grid_search.best_score_))\n","\n","def process_file(file_path):\n","    df = pd.read_csv(file_path)\n","    labels = df['label']\n","    features = df.drop(columns=['subject_id', 'label'])\n","    run_rf_grid_search(features, labels)\n","\n","def main(folder_path):\n","    import os\n","    for file_name in os.listdir(folder_path):\n","        if file_name.startswith(\"features_\") and file_name.endswith(\".csv\"):\n","            file_path = os.path.join(folder_path, file_name)\n","            print(f\"\\nProcessing file: {file_name}\")\n","            process_file(file_path)\n","\n","# Cambia la ruta según corresponda\n","main('/home/ximo/Escritorio/ProyectoTFG/featuresExtended')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_selection import SelectKBest, f_classif\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import GridSearchCV\n","\n","def run_rf_grid_search(features, labels):\n","    pipe = Pipeline([\n","        ('select_k_best', SelectKBest(score_func=f_classif)),\n","        ('random_forest', RandomForestClassifier())\n","    ])\n","\n","    # Definir rangos para 'k' con saltos de 5 en 5, ajusta según necesidad\n","    k_range = list(range(51, features.shape[1], 1))\n","\n","    params = {\n","        'select_k_best__k': k_range,\n","        'random_forest__n_estimators': [100, 200, 300],\n","\n","        'random_forest__max_depth': [None, 10, 20],\n","        'random_forest__min_samples_split': [2, 5, 10],\n","        'random_forest__min_samples_leaf': [2, 4, 6]\n","    }\n","\n","    grid_search = GridSearchCV(pipe, param_grid=params, cv=5, scoring='accuracy', n_jobs=-1)\n","    grid_search.fit(features, labels)\n","    \n","    print(\"Optimized parameters for Random Forest:\", grid_search.best_params_)\n","    print(\"Optimized cross-validation score: {:.2f}\".format(grid_search.best_score_))\n","\n","def process_file(file_path):\n","    df = pd.read_csv(file_path)\n","    labels = df['label']\n","    features = df.drop(columns=['subject_id', 'label'])\n","    run_rf_grid_search(features, labels)\n","\n","def main(folder_path):\n","    import os\n","    for file_name in os.listdir(folder_path):\n","        if file_name.startswith(\"features_\") and file_name.endswith(\".csv\"):\n","            file_path = os.path.join(folder_path, file_name)\n","            print(f\"\\nProcessing file: {file_name}\")\n","            process_file(file_path)\n","\n","# Cambia la ruta según corresponda\n","main('/home/ximo/Escritorio/ProyectoTFG/featuresExtended')\n"]},{"cell_type":"markdown","metadata":{},"source":["Processing file: features_1.csv\n","Optimized parameters for Random Forest: {'random_forest__max_depth': 20, 'random_forest__min_samples_leaf': 4, 'random_forest__min_samples_split': 10, 'random_forest__n_estimators': 100, 'select_k_best__k': 130}\n","Optimized cross-validation score: 0.59\n","\n","Processing file: features_4.csv\n","Optimized parameters for Random Forest: {'random_forest__max_depth': 20, 'random_forest__min_samples_leaf': 6, 'random_forest__min_samples_split': 2, 'random_forest__n_estimators': 100, 'select_k_best__k': 129}\n","Optimized cross-validation score: 0.56\n","\n","Processing file: features_3.csv\n","Optimized parameters for Random Forest: {'random_forest__max_depth': 10, 'random_forest__min_samples_leaf': 4, 'random_forest__min_samples_split': 5, 'random_forest__n_estimators': 200, 'select_k_best__k': 134}\n","Optimized cross-validation score: 0.57\n","\n","Processing file: features_2.csv\n","Optimized parameters for Random Forest: {'random_forest__max_depth': 20, 'random_forest__min_samples_leaf': 4, 'random_forest__min_samples_split': 5, 'random_forest__n_estimators': 300, 'select_k_best__k': 82}\n","Optimized cross-validation score: 0.58"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","import time\n","import warnings\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.feature_selection import SelectKBest, f_classif\n","from sklearn.model_selection import GroupKFold\n","from sklearn.metrics import confusion_matrix\n","from sklearn.exceptions import ConvergenceWarning\n","\n","\n","folder_path = '/home/ximo/Escritorio/ProyectoTFG/featuresExtended'\n","output_path = '/home/ximo/Escritorio/ProyectoTFG/resultsEXTRA'\n","\n","# Diccionario con parámetros optimizados solo para Random Forest\n","optimized_parameters = {\n","    \"features_1.csv\": {\n","        \"Random Forest\": {'random_forest__max_depth': 20, 'random_forest__min_samples_leaf': 4, 'random_forest__min_samples_split': 10, 'random_forest__n_estimators': 100, 'select_k_best__k': 130}\n","    },\n","    \"features_4.csv\": {\n","        \"Random Forest\": {'random_forest__max_depth': 20, 'random_forest__min_samples_leaf': 6, 'random_forest__min_samples_split': 2, 'random_forest__n_estimators': 100, 'select_k_best__k': 129}\n","    },\n","    \"features_3.csv\": {\n","        \"Random Forest\": {'random_forest__max_depth': 10, 'random_forest__min_samples_leaf': 4, 'random_forest__min_samples_split': 5, 'random_forest__n_estimators': 200, 'select_k_best__k': 134}\n","    },\n","    \"features_2.csv\": {\n","        \"Random Forest\": {'random_forest__max_depth': 20, 'random_forest__min_samples_leaf': 4, 'random_forest__min_samples_split': 5, 'random_forest__n_estimators': 300, 'select_k_best__k': 82}\n","    }\n","}\n","\n","# Modelo base para Random Forest\n","models = {\n","    \"Random Forest\": RandomForestClassifier\n","}\n","\n","# Function to create a unique file path if the file already exists\n","def create_unique_file_path(base_path, filename):\n","    counter = 1\n","    original_filename = filename\n","    while os.path.exists(os.path.join(base_path, filename)):\n","        filename = f\"{os.path.splitext(original_filename)[0]}({counter}){os.path.splitext(original_filename)[1]}\"\n","        counter += 1\n","    return os.path.join(base_path, filename)\n","\n","# Function to perform evaluation for a given k and write the results to a file\n","def evaluate_and_save_results(features, labels, subjects, models, model_name, model_params, k, output_path, num_windows):\n","    if not os.path.exists(output_path):\n","        os.makedirs(output_path)\n","\n","    selector = SelectKBest(f_classif, k=k)\n","    selected_features = selector.fit_transform(features, labels)\n","    gkf = GroupKFold(n_splits=len(np.unique(subjects)))\n","\n","    # Remove the pipeline step prefix from the model parameters\n","    clean_params = {key.split('__')[-1]: value for key, value in model_params.items()}\n","\n","    # Ajuste específico para SVM\n","    if model_name == \"SVM\" and clean_params.get('penalty') == 'l1':\n","        clean_params['dual'] = False  # Asegurarse de que dual=False cuando penalty='l1'\n","    \n","    model_cls = models[model_name]\n","    model = model_cls(**clean_params)\n","    cm_global = np.zeros((4, 4))  # Ajusta el tamaño según el número de etiquetas únicas\n","    model_times = []\n","\n","    for train_idx, test_idx in gkf.split(selected_features, labels, groups=subjects):\n","        X_train, X_test = selected_features[train_idx], selected_features[test_idx]\n","        y_train, y_test = labels.iloc[train_idx], labels.iloc[test_idx]\n","\n","        start_time = time.time()\n","        with warnings.catch_warnings():\n","            warnings.simplefilter(\"ignore\", ConvergenceWarning)\n","            model.fit(X_train, y_train)\n","        \n","        end_time = time.time()\n","        predictions = model.predict(X_test)\n","        model_time = end_time - start_time\n","        model_times.append(model_time)\n","\n","        cm = confusion_matrix(y_test, predictions, labels=[0, 1, 2, 3])\n","        cm_global += cm  # Acumular resultados de la matriz de confusión\n","\n","    cm_df = pd.DataFrame(cm_global, index=[0, 1, 2, 3], columns=[0, 1, 2, 3])\n","    filename = f\"conf_matrix_{num_windows}_{model_name}_{k}.csv\"\n","    unique_file_path = create_unique_file_path(output_path, filename)\n","    cm_df.to_csv(unique_file_path)\n","\n","    # Guardar el tiempo de ejecución del modelo\n","    average_time = sum(model_times)\n","    times_file_path = f\"{output_path}/model_times.csv\"\n","    header = not os.path.exists(times_file_path)  # Comprueba si el archivo ya existe\n","    with open(times_file_path, \"a\") as f:\n","        if header:\n","            f.write(\"Model,Window,K,Time(s)\\n\")  # Escribe los encabezados si el archivo no existe\n","            \n","        f.write(f\"{model_name},{num_windows},{k},{average_time}\\n\")\n","\n","# Main processing and evaluation function\n","def process_and_evaluate(file_path, models, optimized_parameters, output_path):\n","    df = pd.read_csv(file_path)\n","    drop_cols = ['subject_id', 'label']\n","    features = df.drop(columns=drop_cols)\n","    labels = df['label']\n","    subjects = df['subject_id']\n","    num_windows = file_path.split('_')[-1].split('.')[0]  # Extract number of windows from filename\n","\n","    file_name = os.path.basename(file_path)\n","    if file_name in optimized_parameters:\n","        for model_name, params in optimized_parameters[file_name].items():\n","            k = params.pop('select_k_best__k')\n","            evaluate_and_save_results(features, labels, subjects, models, model_name, params, k, output_path, num_windows)\n","\n","# Run the processing\n","for file_name in os.listdir(folder_path):\n","    if file_name.startswith(\"features_\") and file_name.endswith(\".csv\"):\n","        file_path = os.path.join(folder_path, file_name)\n","        process_and_evaluate(file_path, models, optimized_parameters, output_path)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOJnYtHBIv8Enmhf4iTycLN","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
