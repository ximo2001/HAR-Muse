{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","from sklearn.svm import SVC\n","from sklearn.svm import LinearSVC\n","from sklearn.ensemble import RandomForestClassifier\n","import xgboost as xgb\n","from sklearn.model_selection import LeaveOneOut, cross_val_score\n","from sklearn.metrics import accuracy_score\n","from sklearn.neighbors import KNeighborsClassifier\n","from tabulate import tabulate\n","from sklearn.metrics import confusion_matrix\n","from sklearn.feature_selection import SelectKBest, f_classif\n","from scipy.fft import fft\n","import time\n","from pyentrp import entropy as ent\n","from sklearn.model_selection import GroupKFold\n","\n","# Function to load and preprocess data\n","def load_data(subject, repetition, experiment_type, minute):\n","    file_path = os.path.join(data_path, f'{subject}_{repetition}_{experiment_type}{minute}.csv')\n","\n","    # Read data, treating potential mixed types as strings, and coercing errors to NaN\n","    data = pd.read_csv(file_path, dtype=str, low_memory=False, on_bad_lines='skip')    \n","\n","    data = data.apply(pd.to_numeric, errors='coerce') \n","\n","    # Label assignment based on experiment type\n","    if experiment_type == 'm':\n","        data['label'] = 0\n","    elif experiment_type == 'l':\n","        data['label'] = 1\n","    elif experiment_type == 'c':\n","        data['label'] = 2\n","    elif experiment_type == 'e':\n","        data['label'] = 3\n","    else:\n","        raise ValueError(\"Invalid experiment_type.\")\n","\n","    return data"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def calculate_total_band_energy(signal):\n","    \"\"\"Calculates the total energy of the frequency band of a signal using FFT.\"\"\"\n","    fft_values = np.fft.fft(signal)\n","    magnitude_squared = np.abs(fft_values) ** 2\n","    total_energy = np.sum(magnitude_squared) / len(signal)\n","    return total_energy\n","\n","def max_power(signal):\n","    \"\"\"Calculates the maximum power of a signal using FFT.\"\"\"\n","    fft_values = np.fft.fft(signal)\n","    power_spectrum = np.abs(fft_values) ** 2 / len(signal)\n","    return np.max(power_spectrum)\n","\n","def shannon_entropy(signal):\n","    \"\"\"Calculates Shannon entropy of a signal.\"\"\"\n","    value, counts = np.unique(signal, return_counts=True)\n","    probabilities = counts / counts.sum()\n","    entropy = -np.sum(probabilities * np.log2(probabilities + 1e-10))  # To avoid log(0)\n","    return entropy\n","\n","def calculate_peak_to_peak(signal):\n","    \"\"\"Calculates the peak-to-peak value of a signal.\"\"\"\n","    peak_to_peak_value = signal.max() - signal.min()\n","    return peak_to_peak_value\n","\n","def differential_entropy(signal):\n","    variance = np.var(signal)\n","    if variance == 0:\n","        return 0  # Avoid log(0), return 0 for a signal with no variability\n","    return 0.5 * np.log(2 * np.pi * np.e * variance)\n","\n","\n","def sample_entropy(signal, m=2, r=None):\n","    try:\n","        std_signal = np.std(signal)\n","        if std_signal == 0:\n","            return 0  # Return a default or placeholder value that maintains consistency\n","        if r is None:\n","            r = 0.2 * std_signal\n","        entropy_value = ent.sample_entropy(signal, m, r)\n","        if len(entropy_value) > 0:\n","            return entropy_value[0]  # Ensure this returns a single value\n","        else:\n","            return 0  # Return a default value if entropy array is empty\n","    except Exception as e:\n","        print(f\"Error calculating sample entropy: {str(e)}\")\n","        return 0  # Return a default value in case of other exceptions\n","\n","\n","\n","def extract_features(data, num_windows):\n","    window_size = int((60*256) / num_windows)  # Adjusted to dataset specifics\n","    features, labels = [], []\n","    for i in range(num_windows):\n","        window_data = data.iloc[i*window_size : (i+1)*window_size]\n","        if len(window_data) < window_size:\n","            raise ValueError(\"NOT ENOUGH DATA FOR 1 MINUTE.\")\n","        \n","        # Drop label from the window data if present\n","        if 'label' in window_data.columns:\n","            labels.append(window_data['label'].iloc[0])\n","            feature_data = window_data.drop(columns='label')\n","        else:\n","            feature_data = window_data\n","\n","        # Calculate features for each channel\n","        means = feature_data.mean()\n","        max_powers = feature_data.apply(max_power)\n","        entropies = feature_data.apply(shannon_entropy)\n","        band_energies = feature_data.apply(calculate_total_band_energy)\n","        peak_to_peak_values = feature_data.apply(calculate_peak_to_peak)\n","        diff_entropies = feature_data.apply(differential_entropy)\n","        sample_entropies = feature_data.apply(sample_entropy)\n","        sample_entropies_array = sample_entropies.values.flatten() if sample_entropies.ndim > 1 else sample_entropies.values\n","\n","        # Combine all features into a single array\n","        combined_features = np.concatenate([\n","            means.values,\n","            max_powers.values,\n","            entropies.values,\n","            band_energies.values,\n","            sample_entropies_array,\n","            diff_entropies.values,\n","            peak_to_peak_values.values            \n","        ])\n","\n","        # Append combined features and labels\n","        features.append(combined_features)\n","\n","    features, labels = np.array(features), np.array(labels)\n","    return features, labels\n","\n","def generate_feature_names(data):\n","    feature_names = []\n","    # Assuming 'data' is a DataFrame with the same structure as your actual feature data\n","    sample_data = data.iloc[:1]  # Take just one row to minimize processing\n","    if 'label' in sample_data.columns:\n","        sample_data = sample_data.drop(columns='label')\n","\n","    for column in sample_data.columns:\n","        feature_names.extend([\n","            f\"mean_{column}\",\n","            f\"max_power_{column}\",\n","            f\"entropy_{column}\",\n","            f\"band_energy_{column}\",\n","            f\"sample_entropy_{column}\", \n","            f\"differential_entropy_{column}\",\n","            f\"peak_to_peak_{column}\"\n","        ])\n","    return feature_names\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def save_features_labels(features, labels, subject_ids, num_windows, feature_names, folder_path):\n","    \"\"\"\n","    Saves features, labels, and subject IDs to a CSV file, ensuring not to overwrite existing files.\n","    :param features: numpy array of features.\n","    :param labels: numpy array of labels.\n","    :param subject_ids: numpy array of subject identifiers.\n","    :param num_windows: number of windows, used for naming the file.\n","    :param folder_path: directory path where the files will be saved.\n","    \"\"\"\n","    # Create the folder if it does not exist\n","    os.makedirs(folder_path, exist_ok=True)\n","    \n","    # Prepare the data for saving\n","    data = np.column_stack((subject_ids, features, labels))\n","    df = pd.DataFrame(data)\n","    df.columns = [\"subject_id\"] + feature_names + [\"label\"]\n","    \n","    # Generate the base file name\n","    base_file_name = os.path.join(folder_path, f\"features_{num_windows}\")\n","    extension = \".csv\"\n","    file_name = base_file_name + extension\n","    counter = 1\n","\n","    # Increment the file name if it already exists\n","    while os.path.exists(file_name):\n","        file_name = f\"{base_file_name}({counter}){extension}\"\n","        counter += 1\n","\n","    # Save the DataFrame to a CSV file\n","    df.to_csv(file_name, index=False)\n","    print(f\"File saved: {file_name}\")"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of feature names: 175\n","Expected number of DataFrame columns: 177\n","File saved: /home/ximo/Escritorio/ProyectoTFG/featuresExtended/features_1.csv\n"]}],"source":["# Path to data and other constants\n","data_path = '/home/ximo/Escritorio/ProyectoTFG/MusePreprocessed'\n","subjects = range(1,31)\n","repetitions = ['1', '2']\n","minutes = ['1', '2', '3']\n","experiment_types = ['m', 'l', 'c', 'e']\n","num_windows_options = [1]\n","folder_name = \"/home/ximo/Escritorio/ProyectoTFG/featuresExtended\"\n","\n","for num_windows in num_windows_options:\n","\n","    # Preload all data and extract features once\n","    all_data = {}\n","    all_features = []\n","    all_labels = []\n","    all_subject_ids = []  \n","\n","    # Load a small sample data to generate feature names\n","    sample_data = load_data(subjects[0], repetitions[0], experiment_types[0], minutes[0])\n","    feature_names = generate_feature_names(sample_data)\n","\n","    print(\"Number of feature names:\", len(feature_names))\n","    print(\"Expected number of DataFrame columns:\", len(feature_names) + 2)  # +2 for \"subject_id\" and \"label\"\n","\n","\n","\n","    for subject in subjects:\n","        subject_data = []\n","        for repetition in repetitions:\n","            for exp_type in experiment_types:\n","                for minute in minutes:\n","                    data = load_data(subject, repetition, exp_type, minute)\n","                    features, labels = extract_features(data, num_windows)\n","                    subject_data.append((features, labels))\n","                    all_features.extend(features)\n","                    all_labels.extend(labels)\n","                    all_subject_ids.extend([subject] * len(features))\n","        all_data[subject] = subject_data\n","\n","    all_features = np.array(all_features)\n","    all_labels = np.array(all_labels)\n","    all_subject_ids = np.array(all_subject_ids)  # Convert list of subject IDs to an array\n","\n","    #Guardamos las features en un ficheros\n","    save_features_labels(all_features, all_labels, all_subject_ids, num_windows, feature_names, folder_name)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOJnYtHBIv8Enmhf4iTycLN","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
